# **Job Market Analysis - Web Scraping System**

[![Python Version](https://img.shields.io/badge/python-3.8%2B-blue)](https://www.python.org/)
[![License](https://img.shields.io/badge/license-MIT-green)](LICENSE)
[![Code Style](https://img.shields.io/badge/code%20style-black-black)](https://github.com/psf/black)

Há»‡ thá»‘ng thu tháº­p vÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u viá»‡c lÃ m tá»« cÃ¡c trang web tuyá»ƒn dá»¥ng táº¡i Viá»‡t Nam, Ä‘Æ°á»£c xÃ¢y dá»±ng báº±ng Python vá»›i kiáº¿n trÃºc OOP.

## **ğŸ“‹ Má»¥c Lá»¥c**

- [Giá»›i Thiá»‡u](#-giá»›i-thiá»‡u)
- [TÃ­nh NÄƒng](#-tÃ­nh-nÄƒng)
- [CÃ i Äáº·t](#-cÃ i-Ä‘áº·t)
- [Cáº¥u TrÃºc Dá»± Ãn](#-cáº¥u-trÃºc-dá»±-Ã¡n)
- [CÃ¡ch Sá»­ Dá»¥ng](#-cÃ¡ch-sá»­-dá»¥ng)
- [Cáº¥u HÃ¬nh](#-cáº¥u-hÃ¬nh)
- [Kiáº¿n TrÃºc](#-kiáº¿n-trÃºc)
- [License](#-license)

## **âœ¨ Giá»›i Thiá»‡u**

Dá»± Ã¡n nÃ y cung cáº¥p giáº£i phÃ¡p tá»± Ä‘á»™ng hÃ³a viá»‡c thu tháº­p dá»¯ liá»‡u viá»‡c lÃ m tá»« cÃ¡c trang web tuyá»ƒn dá»¥ng hÃ ng Ä‘áº§u Viá»‡t Nam. Há»‡ thá»‘ng Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ:

- Thu tháº­p thÃ´ng tin viá»‡c lÃ m theo nhiá»u keyword khÃ¡c nhau
- Xá»­ lÃ½ vÃ  chuáº©n hÃ³a dá»¯ liá»‡u tá»± Ä‘á»™ng
- LÆ°u trá»¯ dá»¯ liá»‡u vÃ o nhiá»u Ä‘á»‹nh dáº¡ng (CSV, Google Sheets)
- Há»— trá»£ phÃ¢n tÃ­ch thá»‹ trÆ°á»ng viá»‡c lÃ m

## **ğŸš€ TÃ­nh NÄƒng**

### **ğŸ“Š Thu Tháº­p Dá»¯ Liá»‡u**
- **Há»— trá»£ Ä‘a nguá»“n**: JobsGo vÃ  TopCV
- **Xá»­ lÃ½ linh hoáº¡t**: Async (cho web khÃ´ng bá»‹ rate limiting) vÃ  Sync (cho web dÃ¬nh rate limiting)
- **Retry thÃ´ng minh**: Tá»± Ä‘á»™ng xá»­ lÃ½ rate limiting vÃ  timeout
- **PhÃ¢n trang tá»± Ä‘á»™ng**: Tá»± Ä‘á»™ng xÃ¡c Ä‘á»‹nh sá»‘ trang cáº§n crawl

### **ğŸ”§ Xá»­ LÃ½ Dá»¯ Liá»‡u**
- **Chuáº©n hÃ³a lÆ°Æ¡ng**: Chuyá»ƒn Ä‘á»•i vá» Ä‘Æ¡n vá»‹ triá»‡u VND
- **TrÃ­ch xuáº¥t ká»¹ nÄƒng**: Tá»± Ä‘á»™ng phÃ¡t hiá»‡n tools tá»« mÃ´ táº£
- **Xá»­ lÃ½ Ä‘á»‹a Ä‘iá»ƒm**: Chuáº©n hÃ³a format Ä‘á»‹a Ä‘iá»ƒm
- **Loáº¡i bá» duplicate**: Dá»±a trÃªn job_id vÃ  thá»i gian

### **ğŸ’¾ LÆ°u Trá»¯**
- **CSV**: LÆ°u trá»¯ local vá»›i append mode
- **Google Sheets**: Äá»“ng bá»™ lÃªn cloud
- **Tá»± Ä‘á»™ng deduplicate**: Giá»¯ dá»¯ liá»‡u sáº¡ch

## **âš™ï¸ CÃ i Äáº·t**

### **YÃªu Cáº§u Há»‡ Thá»‘ng**
- Python 3.8 trá»Ÿ lÃªn
- pip (Python package manager)

### **CÃ i Äáº·t Dependencies**

```bash
# Clone repository
git clone https://github.com/hoan110102/job-scraping.git
cd job-scraping

# Táº¡o virtual environment (tuá»³ chá»n)
python -m venv venv
# Windows
venv\Scripts\activate
# Mac/Linux
source venv/bin/activate

# CÃ i Ä‘áº·t dependencies
pip install -r requirements.txt
```

### **requirements.txt**
```txt
httpx==0.25.0
beautifulsoup4==4.12.2
lxml==4.9.3
pandas==2.0.3
numpy==1.24.3
gspread==5.11.0
google-auth==2.22.0
google-auth-oauthlib==1.0.0
google-api-python-client==2.95.0
unidecode==1.3.6
python-dotenv==1.0.0
```

## **ğŸ“ Cáº¥u TrÃºc Dá»± Ãn**

```
job-scraping/
â”œâ”€â”€ scrapers/                    # CÃ¡c module thu tháº­p dá»¯ liá»‡u
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ jobsgo_scraper.py       # Scraper cho JobsGo (async)
â”‚   â””â”€â”€ topcv_scraper.py        # Scraper cho TopCV (sync)
â”œâ”€â”€ utils/                      # Tiá»‡n Ã­ch vÃ  helpers
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ common.py              # Common functions vÃ  classes
â”‚   â””â”€â”€ config.py              # Configuration
â”œâ”€â”€ data_processor/             # Xá»­ lÃ½ dá»¯ liá»‡u
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ processor.py           # Xá»­ lÃ½ vÃ  chuáº©n hÃ³a dá»¯ liá»‡u
â”œâ”€â”€ credentials/                # Credentials (khÃ´ng commit)
â”‚   â””â”€â”€ credentials.json       # Google Service Account
â”œâ”€â”€ data/                       # Dá»¯ liá»‡u Ä‘Ã£ thu tháº­p
â”‚   â””â”€â”€ final_crawl_data.csv   # Káº¿t quáº£
â”œâ”€â”€ image/                      # HÃ¬nh áº£nh vÃ  dashboard
â”œâ”€â”€ venv_scraping/              # Virtual environment
â”œâ”€â”€ main.py                     # Entry point chÃ­nh
â”œâ”€â”€ requirements.txt           # Dependencies
â””â”€â”€ README.md                  # TÃ i liá»‡u nÃ y
```

## **ğŸš€ CÃ¡ch Sá»­ Dá»¥ng**

### **Cháº¡y ToÃ n Bá»™ Há»‡ Thá»‘ng**

```bash
python main.py
```

### **Output**
Há»‡ thá»‘ng sáº½:
1. Thu tháº­p dá»¯ liá»‡u tá»« JobsGo (async)
2. Thu tháº­p dá»¯ liá»‡u tá»« TopCV (sync)
3. Xá»­ lÃ½ vÃ  chuáº©n hÃ³a dá»¯ liá»‡u
4. LÆ°u vÃ o `data/final_crawl_data.csv`
5. Upload lÃªn Google Sheets (náº¿u Ä‘Æ°á»£c cáº¥u hÃ¬nh)

### **Custom Keywords**

Máº·c Ä‘á»‹nh há»‡ thá»‘ng sáº½ crawl cÃ¡c keyword:
```python
key_words = [
    "Business Analyst",
    "Data Analyst", 
    "Data Engineer",
    "Data Scientist",
    "Machine Learning",
]
```

Äá»ƒ thay Ä‘á»•i, sá»­a trong `main.py`:
```python
key_words = [
    "Your Keyword 1",
    "Your Keyword 2",
    # ... thÃªm keywords má»›i
]
```

## **ğŸ”§ Cáº¥u HÃ¬nh**

### **Cáº¥u HÃ¬nh Google Sheets**

1. **Táº¡o Google Cloud Project**:
   - Truy cáº­p [Google Cloud Console](https://console.cloud.google.com/)
   - Táº¡o project má»›i

2. **KÃ­ch hoáº¡t APIs**:
   - Google Sheets API
   - Google Drive API

3. **Táº¡o Service Account**:
   - VÃ o IAM & Admin â†’ Service Accounts
   - Táº¡o service account má»›i
   - Download JSON credentials

4. **Cáº¥u hÃ¬nh trong project**:
   - Äáº·t file `credentials.json` vÃ o folder `credentials/`
   - Chia sáº» Google Sheet vá»›i email cá»§a service account

### **Cáº¥u HÃ¬nh Headers vÃ  Timeout**

Sá»­a file `utils/config.py`:
```python
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    # ... thÃªm headers tuá»³ chá»‰nh
}

# Thá»i gian timeout (giÃ¢y)
TIMEOUT = 30
```

## **ğŸ—ï¸ Kiáº¿n TrÃºc**

### **Design Pattern**
- **Factory Pattern**: Táº¡o HTTP client (sync/async)
- **Strategy Pattern**: Xá»­ lÃ½ dá»¯ liá»‡u khÃ¡c nhau cho tá»«ng website
- **Template Method**: Base class cho scraper

### **Data Flow**
```
1. Main â†’ khá»Ÿi táº¡o scraper
2. Scraper â†’ HTTP Client â†’ fetch HTML
3. HTML â†’ BeautifulSoup â†’ parse data
4. Raw Data â†’ Data Processor â†’ clean data
5. Clean Data â†’ Storage (CSV/Google Sheets)
```

## **ğŸ“Š Data Schema**

### **Raw Data Fields**
| Field | Type | Description |
|-------|------|-------------|
| source | string | "JobsGo" hoáº·c "TopCV" |
| job_type | string | Loáº¡i cÃ´ng viá»‡c (Data Analyst, etc.) |
| url_job | string | URL chi tiáº¿t cÃ´ng viá»‡c |
| job_id | string | ID duy nháº¥t cá»§a job |
| posting_date | string | NgÃ y Ä‘Äƒng (dd-mm-yyyy) |
| job_title | string | TiÃªu Ä‘á» cÃ´ng viá»‡c |
| salary | string | Má»©c lÆ°Æ¡ng (raw) |
| location | string | Äá»‹a Ä‘iá»ƒm lÃ m viá»‡c |
| exp | string | YÃªu cáº§u kinh nghiá»‡m |
| level | string | Cáº¥p báº­c |
| industry | string | NgÃ nh nghá» |
| company_name | string | TÃªn cÃ´ng ty |
| description | string | MÃ´ táº£ cÃ´ng viá»‡c |

### **Processed Data Fields**
| Field | Type | Description |
|-------|------|-------------|
| month | int | ThÃ¡ng thu tháº­p |
| year | int | NÄƒm thu tháº­p |
| salary | float | LÆ°Æ¡ng (triá»‡u VND) |
| exp | float | Kinh nghiá»‡m (nÄƒm) |
| tools | string | CÃ¡c cÃ´ng cá»¥/ká»¹ nÄƒng phÃ¡t hiá»‡n |

## **ğŸ› ï¸ PhÃ¡t Triá»ƒn**

### **ThÃªm Scraper Má»›i**

1. Táº¡o file má»›i trong folder `scrapers/`:
```python
# scrapers/new_scraper.py
from utils.common import Create_Client_Sync, Get_Soup_Sync, Crawl_Data
import pandas as pd

def scrape_new_site(key_word=None):
    # Implementation
    pass
```

2. Import vÃ o `main.py`:
```python
from scrapers.new_scraper import scrape_new_site
```

3. ThÃªm vÃ o pipeline trong `main.py`

## **âš ï¸ Best Practices & Notes**

### **Rate Limiting**
- JobsGo: Sá»­ dá»¥ng async vá»›i delay há»£p lÃ½
- TopCV: Sá»­ dá»¥ng sync Ä‘á»ƒ trÃ¡nh bá»‹ block
- LuÃ´n check `robots.txt` cá»§a tá»«ng website

### **Error Handling**
- Retry logic: 5 láº§n thá»­ vá»›i exponential backoff
- Logging: In thÃ´ng tin chi tiáº¿t khi cÃ³ lá»—i
- Graceful shutdown: ÄÃ³ng connection Ä‘Ãºng cÃ¡ch

### **Performance**
- Async cho I/O bound operations
- Batch processing cho large datasets
- Memory management vá»›i large DataFrames

## **ğŸ“„ License**

Distributed under the MIT License. See `LICENSE` for more information.

## **ğŸ“ LiÃªn Há»‡**

Author: [hoan110102](https://github.com/hoan110102)

Project Link: [https://github.com/hoan110102/job-scraping](https://github.com/hoan110102/job-scraping)

## **ğŸ™ Acknowledgements**

- [httpx](https://www.python-httpx.org/) - HTTP client cho async/sync requests
- [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/) - HTML parsing
- [pandas](https://pandas.pydata.org/) - Data manipulation
- [gspread](https://docs.gspread.org/) - Google Sheets API

---

**â­ Náº¿u báº¡n tháº¥y dá»± Ã¡n há»¯u Ã­ch, hÃ£y star repository nÃ y!**
